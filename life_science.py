import os
import requests
import random
from datetime import datetime
import wikipediaapi

class LifeScienceBot:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'deepseek-reasoner')
        self.feishu_url = os.getenv('LIFE_FEISHU_URL')
        
        # æƒå¨äº‹å®æ¥æºåº“ï¼ˆæ¯æ—¥éšæœºé€‰ä¸€ä¸ªä¸»é¢˜æ·±æŒ–ï¼‰
        self.topics = [
            "sleep_circadian_rhythm",  # ç¡çœ ä¸æ˜¼å¤œèŠ‚å¾‹
            "nutrition_metabolism",    # è¥å…»ä»£è°¢ï¼ˆæœ‰ä¸´åºŠè¯æ®çš„ï¼‰
            "exercise_physiology",     # è¿åŠ¨ç”Ÿç†
            "cognitive_psychology",    # è®¤çŸ¥å¿ƒç†
            "microbiome_gut_health",   # è‚ é“èŒç¾¤ï¼ˆæœ‰Cell/Natureå®è¯çš„ï¼‰
            "light_vision_health",     # å…‰çº¿ä¸è§†åŠ›å¥åº·
        ]
    
    def fetch_wikipedia_fact(self):
        """ä»Wikipediaè·å–ä»Šæ—¥ç²¾é€‰ï¼ˆç»è¿‡åŒè¡Œè¯„è®®çš„ç§‘æ™®ï¼‰"""
        wiki = wikipediaapi.Wikipedia('DailyScienceBot/1.0', 'en')
        
        # è·å–"On this day"å†å²ä¸Šçš„ç§‘å­¦å‘ç°ï¼Œæˆ–éšæœºé«˜è´¨é‡è¯æ¡
        topics = [
            "Circadian rhythm", "Melatonin", "Vitamin D", 
            "Hypertension", "Caffeine", "Blue light",
            "Gut microbiota", "REM sleep", "Insulin resistance"
        ]
        
        topic = random.choice(topics)
        page = wiki.page(topic)
        
        if not page.exists():
            return None
            
        return {
            'title': topic,
            'summary': page.summary[:800],
            'url': page.fullurl,
            'source': 'Wikipedia (CC BY-SA)'
        }
    
    def fetch_pubmed_health_tip(self):
        """ä»PubMedè·å–ä»Šæ—¥å¥åº·å¾ªè¯ç ”ç©¶ï¼ˆè¿‘7å¤©é«˜åˆ†ç»¼è¿°ï¼‰"""
        # æœç´¢é«˜è´¨é‡å¥åº·å»ºè®®ï¼ˆMetaåˆ†ææˆ–RCTï¼‰
        query = "(sleep[Title] OR diet[Title] OR exercise[Title]) AND (meta-analysis[Title] OR randomized[Title])"
        
        url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
        params = {
            'db': 'pubmed',
            'term': query,
            'retmax': 5,
            'sort': 'date',
            'retmode': 'json',
            'datetype': 'pdat',  # å‘è¡¨æ—¥æœŸ
            'reldate': 7  # æœ€è¿‘7å¤©
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            idlist = data['esearchresult']['idlist']
            
            if not idlist:
                return None
                
            # è·å–ç¬¬ä¸€ç¯‡è¯¦æƒ…
            fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
            fetch_params = {
                'db': 'pubmed',
                'id': idlist[0],
                'retmode': 'json'
            }
            
            fetch_resp = requests.get(fetch_url, params=fetch_params, timeout=10)
            article = fetch_resp.json()['result'][idlist[0]]
            
            return {
                'title': article.get('title', ''),
                'journal': article.get('source', ''),
                'author': article.get('sortfirstauthor', ''),
                'pmid': idlist[0],
                'url': f"https://pubmed.ncbi.nlm.nih.gov/{idlist[0]}/",
                'source': f"PubMed - {article.get('source', '')}"
            }
        except:
            return None
    
    def verify_and_summarize(self, wiki_data, pubmed_data):
        """ç”¨DeepSeekæ•´åˆå¹¶å¼ºè°ƒè¯æ®ç­‰çº§"""
        
        content = f"""
ä»Šæ—¥ç§‘æ™®ä¸»é¢˜ï¼š{wiki_data['title'] if wiki_data else 'å¥åº·æ–°çŸ¥'}

èƒŒæ™¯çŸ¥è¯†ï¼ˆæ¥è‡ªç™¾ç§‘ï¼‰ï¼š
{wiki_data['summary'] if wiki_data else 'æš‚æ— ç™¾ç§‘æ¡ç›®'}

æœ€æ–°ç ”ç©¶ï¼ˆæ¥è‡ªPubMedï¼‰ï¼š
{pubmed_data['title'] if pubmed_data else 'ä»Šæ—¥æ— æ–°ç ”ç©¶'}
æ¥æºæœŸåˆŠï¼š{pubmed_data['journal'] if pubmed_data else 'N/A'}
"""
        
        prompt = f"""ä½ æ˜¯ä¸€ä½å¾ªè¯åŒ»å­¦ç§‘æ™®ä½œå®¶ï¼Œè¯·å°†ä»¥ä¸‹ä¿¡æ¯æ”¹å†™ä¸ºã€æœ‰æ˜ç¡®æ¥æºæ ‡ç­¾ã€‘çš„ç”Ÿæ´»å»ºè®®ï¼ˆæ€»å­—æ•°<400å­—ï¼‰ã€‚å¿…é¡»éµå¾ªè§„åˆ™ï¼š

ã€å†…å®¹ã€‘
{content}

ã€è¾“å‡ºæ ¼å¼ - ä¸¥æ ¼éµå®ˆã€‘ï¼š

ğŸ§  **ä»Šæ—¥å†·çŸ¥è¯†**
ï¼ˆç”¨1å¥è¯è®²ä¸€ä¸ªåç›´è§‰çš„ç§‘å­¦äº‹å®ï¼Œå¸¦âš ï¸è­¦ç¤ºæˆ–âœ…å»ºè®®ï¼‰

ğŸ“– **ä¸ºä»€ä¹ˆï¼Ÿ**
ï¼ˆè§£é‡Šæœºåˆ¶ï¼Œ100å­—å†…ï¼Œç”¨å¤§ç™½è¯ï¼‰

ğŸ”¬ **è¯æ®æ¥æº**ï¼ˆå¿…é¡»æ˜ç¡®æ ‡æ³¨ï¼‰ï¼š
- âœ… **å¼ºè¯æ®**ï¼ˆæ¥è‡ªï¼š{pubmed_data['journal'] if pubmed_data else 'Cochraneç³»ç»Ÿè¯„ä»·/Metaåˆ†æ'}ï¼‰ï¼šä¸€å¥è¯ç»“è®º
- ğŸ“š **å‚è€ƒçŸ¥è¯†**ï¼ˆæ¥è‡ªï¼šWikipedia/WHOæŒ‡å—ï¼‰ï¼šèƒŒæ™¯è¡¥å……
- âš ï¸ **æ³¨æ„äº‹é¡¹**ï¼šä»€ä¹ˆäººç¾¤ä¸é€‚ç”¨ï¼Ÿï¼ˆå¦‚ï¼šå­•å¦‡/æ…¢æ€§ç—…æ‚£è€…éœ€å’¨è¯¢åŒ»ç”Ÿï¼‰

âŒ **å¸¸è§è°£è¨€æ¾„æ¸…**ï¼ˆé‡è¦ï¼ï¼‰ï¼š
é’ˆå¯¹è¿™ä¸ªä¸»é¢˜ï¼Œå¸‚é¢ä¸Šæµä¼ çš„é”™è¯¯è¯´æ³•ï¼ˆå¦‚"ç¡å‰å–ç‰›å¥¶åŠ©çœ "ç­‰ä¼ªç§‘å­¦ï¼‰ï¼Œç”¨âŒæ ‡è®°å¹¶ç®€è¦è¾Ÿè°£ã€‚

ã€ä¸¥ç¦ã€‘ï¼š
- ç¦æ­¢å‡ºç°"ä¸­åŒ»è®¤ä¸º"ã€"ä¸“å®¶è¡¨ç¤º"ç­‰æ¨¡ç³Šæ¥æº
- ç¦æ­¢æ¨èä¿å¥å“/å…·ä½“å“ç‰Œ
- ç¦æ­¢ç»å¯¹åŒ–è¡¨è¿°ï¼ˆ"ä¸€å®š"ã€"è‚¯å®š"ï¼‰ï¼Œæ”¹ç”¨"ç ”ç©¶æ˜¾ç¤º"ã€"è¯æ®è¡¨æ˜"
"""
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.7,
            'max_tokens': 800
        }
        
        try:
            response = requests.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )
            return response.json()['choices'][0]['message']['content']
        except Exception as e:
            return f"ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def run(self):
        # è·å–æ•°æ®
        wiki_fact = self.fetch_wikipedia_fact()
        pubmed_study = self.fetch_pubmed_health_tip()
        
        if not wiki_fact and not pubmed_study:
            self.send_feishu("ğŸ“­ ä»Šæ—¥ç§‘æ™®ç´ æè·å–å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥ç½‘ç»œ")
            return
        
        # ç”Ÿæˆå†…å®¹
        content = self.verify_and_summarize(wiki_fact, pubmed_study)
        
        # æ·»åŠ é¡µè„šæ¥æº
        footer = f"""
---
ğŸ“š **ä»Šæ—¥æ¥æºæ ¸æŸ¥**ï¼š
â€¢ ç™¾ç§‘æ¥æºï¼š{wiki_fact['source'] if wiki_fact else 'N/A'} | ğŸ”— {wiki_fact['url'] if wiki_fact else ''}
â€¢ ç ”ç©¶æ¥æºï¼š{pubmed_study['source'] if pubmed_study else 'N/A'} | ğŸ”— {pubmed_study['url'] if pubmed_study else ''}
âš–ï¸ **å…è´£å£°æ˜**ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›ç§‘æ™®ï¼Œä¸ä½œä¸ºåŒ»ç–—å»ºè®®ï¼Œå…·ä½“è¯Šç–—è¯·å’¨è¯¢åŒ»å¸ˆã€‚
        """
        
        self.send_feishu(content + footer)
        print("ç”Ÿæ´»ç§‘æ™®æ¨é€æˆåŠŸ")
    
    def send_feishu(self, text):
        if not self.feishu_url:
            print("æœªé…ç½®é£ä¹¦")
            return
            
        payload = {
            "msg_type": "text",
            "content": {"text": f"ğŸŒŸ **å¾ªè¯ç”Ÿæ´»** | {datetime.now().strftime('%m-%d')}\n\n{text}"}
        }
        requests.post(self.feishu_url, json=payload)

if __name__ == '__main__':
    bot = LifeScienceBot()
    bot.run()
