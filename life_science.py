import os
import requests
import random
from datetime import datetime
import wikipediaapi

class LifeScienceBot:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'deepseek-reasoner')
        self.feishu_url = os.getenv('LIFE_FEISHU_URL')
        
        self.topics = [
            "sleep_circadian_rhythm",
            "nutrition_metabolism", 
            "exercise_physiology",
            "cognitive_psychology",
            "microbiome_gut_health",
            "light_vision_health",
        ]
    
    def fetch_wikipedia_fact(self):
        """ä»Wikipediaè·å–ä»Šæ—¥ç²¾é€‰"""
        try:
            wiki = wikipediaapi.Wikipedia('DailyScienceBot/1.0', 'en')
            
            topics = [
                "Circadian rhythm", "Melatonin", "Vitamin D", 
                "Hypertension", "Caffeine", "Blue light",
                "Gut microbiota", "REM sleep", "Insulin resistance",
                "Hydration", "Fiber", "Protein intake"
            ]
            
            topic = random.choice(topics)
            print(f"æ­£åœ¨æŸ¥è¯¢Wiki: {topic}")
            
            page = wiki.page(topic)
            
            if not page.exists():
                print(f"Wikié¡µé¢ä¸å­˜åœ¨: {topic}")
                return None
                
            return {
                'title': topic,
                'summary': page.summary[:800],
                'url': page.fullurl,
                'source': 'Wikipedia (CC BY-SA)'
            }
        except Exception as e:
            print(f"Wikiè·å–å¤±è´¥: {str(e)}")
            return None
    
    def fetch_pubmed_health_tip(self):
        """ä»PubMedè·å–ä»Šæ—¥å¥åº·å¾ªè¯ç ”ç©¶"""
        try:
            query = "(sleep[Title] OR diet[Title] OR exercise[Title]) AND (meta-analysis[Title] OR randomized[Title])"
            
            url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': query,
                'retmax': 5,
                'sort': 'date',
                'retmode': 'json',
                'datetype': 'pdat',
                'reldate': 7
            }
            
            print("æ­£åœ¨æŸ¥è¯¢PubMed...")
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            idlist = data['esearchresult']['idlist']
            
            if not idlist:
                print("PubMedæœªæ‰¾åˆ°æ–°æ–‡çŒ®")
                return None
                
            fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
            fetch_params = {
                'db': 'pubmed',
                'id': idlist[0],
                'retmode': 'json'
            }
            
            fetch_resp = requests.get(fetch_url, params=fetch_params, timeout=10)
            article = fetch_resp.json()['result'][idlist[0]]
            
            return {
                'title': article.get('title', ''),
                'journal': article.get('source', ''),
                'author': article.get('sortfirstauthor', ''),
                'pmid': idlist[0],
                'url': f"https://pubmed.ncbi.nlm.nih.gov/{idlist[0]}/",
                'source': f"PubMed - {article.get('source', '')}"
            }
        except Exception as e:
            print(f"PubMedè·å–å¤±è´¥: {str(e)}")
            return None
    
    def verify_and_summarize(self, wiki_data, pubmed_data):
        """ç”¨DeepSeekæ•´åˆå¹¶å¼ºè°ƒè¯æ®ç­‰çº§"""
        try:
            wiki_title = wiki_data['title'] if wiki_data else 'å¥åº·æ–°çŸ¥'
            wiki_summary = wiki_data['summary'] if wiki_data else 'æš‚æ— ç™¾ç§‘æ¡ç›®'
            pubmed_title = pubmed_data['title'] if pubmed_data else 'ä»Šæ—¥æ— æ–°ç ”ç©¶'
            pubmed_journal = pubmed_data['journal'] if pubmed_data else 'N/A'
            
            content = f"""
ä»Šæ—¥ç§‘æ™®ä¸»é¢˜ï¼š{wiki_title}

èƒŒæ™¯çŸ¥è¯†ï¼ˆæ¥è‡ªç™¾ç§‘ï¼‰ï¼š
{wiki_summary}

æœ€æ–°ç ”ç©¶ï¼ˆæ¥è‡ªPubMedï¼‰ï¼š
{pubmed_title}
æ¥æºæœŸåˆŠï¼š{pubmed_journal}
"""
            
            prompt = f"""ä½ æ˜¯ä¸€ä½å¾ªè¯åŒ»å­¦ç§‘æ™®ä½œå®¶ï¼Œè¯·å°†ä»¥ä¸‹ä¿¡æ¯æ”¹å†™ä¸ºã€æœ‰æ˜ç¡®æ¥æºæ ‡ç­¾ã€‘çš„ç”Ÿæ´»å»ºè®®ï¼ˆæ€»å­—æ•°<400å­—ï¼‰ã€‚

ã€é‡è¦æ ¼å¼è¦æ±‚ - ä¸¥æ ¼éµå®ˆã€‘ï¼š
âŒ ç¦æ­¢ä½¿ç”¨ä»»ä½•Markdownç¬¦å·
âœ… åªå…è®¸ä½¿ç”¨ï¼šemojiã€ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€æ¢è¡Œã€ç©ºæ ¼
âœ… å±‚çº§ç”¨emojiè¡¨ç¤ºï¼šğŸ§  å†·çŸ¥è¯†ï¼ŒğŸ“– è§£é‡Šï¼ŒğŸ”¬ æ¥æºï¼ŒâŒ è¾Ÿè°£
âœ… åˆ—è¡¨ç”¨ â€¢ ç¬¦å·ï¼ˆä¸­æ–‡è¾“å…¥æ³•é‡Œçš„ç‚¹ï¼‰

ã€å†…å®¹ã€‘
{content}

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼š

ğŸ§  ä»Šæ—¥å†·çŸ¥è¯†
ï¼ˆç”¨1å¥è¯è®²ä¸€ä¸ªåç›´è§‰çš„ç§‘å­¦äº‹å®ï¼‰

ğŸ“– ä¸ºä»€ä¹ˆï¼Ÿ
ï¼ˆè§£é‡Šæœºåˆ¶ï¼Œ100å­—å†…ï¼Œç”¨å¤§ç™½è¯ï¼‰

ğŸ”¬ è¯æ®æ¥æº
â€¢ âœ… å¼ºè¯æ®ï¼ˆæ¥è‡ªï¼š{pubmed_journal}ï¼‰ï¼šä¸€å¥è¯ç»“è®º
â€¢ ğŸ“š å‚è€ƒçŸ¥è¯†ï¼ˆæ¥è‡ªï¼šWikipediaï¼‰ï¼šèƒŒæ™¯è¡¥å……
â€¢ âš ï¸ æ³¨æ„äº‹é¡¹ï¼šä»€ä¹ˆäººç¾¤ä¸é€‚ç”¨ï¼Ÿ

âŒ å¸¸è§è°£è¨€æ¾„æ¸…
ï¼ˆé’ˆå¯¹è¿™ä¸ªä¸»é¢˜ï¼Œå¸‚é¢ä¸Šæµä¼ çš„é”™è¯¯è¯´æ³•ï¼Œç”¨âŒæ ‡è®°ï¼‰

ã€ä¸¥ç¦ã€‘ï¼š
â€¢ ç¦æ­¢å‡ºç°"ä¸­åŒ»è®¤ä¸º"ã€"ä¸“å®¶è¡¨ç¤º"ç­‰æ¨¡ç³Šæ¥æº
â€¢ ç¦æ­¢æ¨èä¿å¥å“/å…·ä½“å“ç‰Œ
â€¢ ç¦æ­¢ç»å¯¹åŒ–è¡¨è¿°ï¼Œæ”¹ç”¨"ç ”ç©¶æ˜¾ç¤º"
â€¢ ç¦æ­¢ä»»ä½•Markdownç¬¦å·
"""
            
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': self.model,
                'messages': [{'role': 'user', 'content': prompt}],
                'temperature': 0.7,
                'max_tokens': 800
            }
            
            print("æ­£åœ¨è°ƒç”¨DeepSeekåˆ†æ...")
            response = requests.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )
            
            if response.status_code != 200:
                print(f"DeepSeek APIé”™è¯¯: {response.status_code} - {response.text}")
                return f"âš ï¸ AIåˆ†æå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                
            result = response.json()
            
            if 'choices' not in result or not result['choices']:
                print(f"DeepSeekè¿”å›å¼‚å¸¸: {result}")
                return "âš ï¸ AIè¿”å›æ ¼å¼å¼‚å¸¸"
            
            content_result = result['choices'][0]['message']['content']
            
            # åå¤„ç†ä¿é™©
            content_result = (content_result
                             .replace('#', '')
                             .replace('**', '')
                             .replace('*', 'â€¢')
                             .replace('- ', 'â€¢ ')
                             .replace('`', '')
                             .replace('>', '')
                             .replace('###', '')
                             .replace('##', ''))
            
            return content_result
            
        except Exception as e:
            print(f"ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return f"âš ï¸ å†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def run(self):
        print("å¼€å§‹è·å–ç”Ÿæ´»ç§‘æ™®æ•°æ®...")
        wiki_fact = self.fetch_wikipedia_fact()
        pubmed_study = self.fetch_pubmed_health_tip()
        
        print(f"Wikiè·å–ç»“æœ: {'æˆåŠŸ' if wiki_fact else 'å¤±è´¥'}")
        print(f"PubMedè·å–ç»“æœ: {'æˆåŠŸ' if pubmed_study else 'å¤±è´¥'}")
        
        if not wiki_fact and not pubmed_study:
            self.send_feishu("ğŸ“­ ä»Šæ—¥ç§‘æ™®ç´ æè·å–å¤±è´¥\nå¯èƒ½åŸå› ï¼š\nâ€¢ Wikipedia APIè¢«å¢™\nâ€¢ PubMedæ— æ–°æ–‡çŒ®\nâ€¢ ç½‘ç»œè¶…æ—¶")
            return
        
        print("å¼€å§‹ç”Ÿæˆå†…å®¹...")
        content = self.verify_and_summarize(wiki_fact, pubmed_study)
        
        if not content or len(content.strip()) < 50:
            print(f"å†…å®¹ç”Ÿæˆå¼‚å¸¸ï¼Œé•¿åº¦: {len(content) if content else 0}")
            content = "âš ï¸ å†…å®¹ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥DeepSeek APIçŠ¶æ€"
        
        footer = f"""
é“¾æ¥æ ¸æŸ¥ï¼š
â€¢ ç™¾ç§‘æ¥æºï¼š{wiki_fact['source'] if wiki_fact else 'N/A'} {wiki_fact['url'] if wiki_fact else 'æ— '}
â€¢ ç ”ç©¶æ¥æºï¼š{pubmed_study['source'] if pubmed_study else 'N/A'} {pubmed_study['url'] if pubmed_study else 'æ— '}
âš–ï¸ å…è´£å£°æ˜ï¼šä»¥ä¸Šä¿¡æ¯ä»…ä¾›ç§‘æ™®ï¼Œä¸ä½œä¸ºåŒ»ç–—å»ºè®®ï¼Œå…·ä½“è¯Šç–—è¯·å’¨è¯¢åŒ»å¸ˆã€‚
"""
        
        full_message = content + footer
        self.send_feishu(full_message)
        print("ç”Ÿæ´»ç§‘æ™®æ¨é€æˆåŠŸ")
    
    def send_feishu(self, text):
        if not self.feishu_url:
            print("é”™è¯¯ï¼šæœªé…ç½®é£ä¹¦Webhook")
            return
            
        try:
            payload = {
                "msg_type": "text",
                "content": {"text": f"ğŸŒŸ å¾ªè¯ç”Ÿæ´» | {datetime.now().strftime('%m-%d')}\n\n{text}"}
            }
            
            response = requests.post(self.feishu_url, json=payload)
            print(f"é£ä¹¦æ¨é€ç»“æœ: {response.status_code}")
            
            if response.status_code != 200:
                print(f"é£ä¹¦æ¨é€å¤±è´¥: {response.text}")
                
        except Exception as e:
            print(f"é£ä¹¦æ¨é€å¼‚å¸¸: {str(e)}")

if __name__ == '__main__':
    bot = LifeScienceBot()
    bot.run()
