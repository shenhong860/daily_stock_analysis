import os
import requests
import json
import random
import feedparser
from datetime import datetime
from bs4 import BeautifulSoup

class LifeScienceWeb:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'deepseek-reasoner')
        self.feishu_url = os.getenv('LIFE_FEISHU_URL')
        
    def fetch_zhihu_health(self):
        """æŠ“å–çŸ¥ä¹å¥åº·è¯é¢˜çƒ­æ¦œ"""
        try:
            # çŸ¥ä¹çƒ­æ¦œAPIï¼ˆå…¬å¼€ï¼‰
            url = "https://www.zhihu.com/api/v3/feed/topstory/hot-lists/total?limit=50"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            data = response.json()
            
            # ç­›é€‰å¥åº·ç›¸å…³è¯é¢˜
            health_keywords = ['å¥åº·', 'åŒ»å­¦', 'åŒ»ç”Ÿ', 'ç–¾ç—…', 'å‡è‚¥', 'ç¡çœ ', 'è¥å…»', 'è¿åŠ¨', 'ç–«è‹—', 'ä½“æ£€']
            health_items = []
            
            for item in data.get('data', []):
                title = item.get('target', {}).get('title', '')
                if any(k in title for k in health_keywords):
                    health_items.append({
                        'title': title,
                        'url': item.get('target', {}).get('url', ''),
                        'source': 'çŸ¥ä¹çƒ­æ¦œ'
                    })
            
            if health_items:
                return random.choice(health_items[:5])  # å‰5ä¸ªéšæœºé€‰1ä¸ª
        except Exception as e:
            print(f"çŸ¥ä¹æŠ“å–å¤±è´¥: {str(e)}")
        return None
    
    def fetch_who_daily(self):
        """æŠ“å–WHOæ¯æ—¥å¥åº·æç¤º"""
        try:
            # WHOæ–°é—»RSS
            url = "https://www.who.int/rss-feeds/news-english.xml"
            feed = feedparser.parse(url)
            
            if feed.entries:
                entry = feed.entries[0]  # æœ€æ–°ä¸€æ¡
                return {
                    'title': entry.title,
                    'summary': entry.summary[:500] if hasattr(entry, 'summary') else '',
                    'url': entry.link,
                    'source': 'WHO'
                }
        except Exception as e:
            print(f"WHOæŠ“å–å¤±è´¥: {str(e)}")
        return None
    
    def fetch_pubmed_today(self):
        """æŠ“å–ä»Šæ—¥PubMedå¥åº·ç§‘æ™®ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # æœç´¢è¿‘7å¤©çš„é«˜å…³æ³¨åº¦å¥åº·ä¸»é¢˜
            query = "(health[Title] OR diet[Title] OR sleep[Title]) AND (review[Publication Type])"
            url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
            params = {
                'db': 'pubmed',
                'term': query,
                'retmax': 3,
                'sort': 'date',
                'retmode': 'json',
                'reldate': 7  # è¿‘7å¤©
            }
            
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            idlist = data['esearchresult']['idlist']
            
            if idlist:
                # å–ç¬¬ä¸€ç¯‡è¯¦æƒ…
                fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi"
                fetch_params = {
                    'db': 'pubmed',
                    'id': idlist[0],
                    'retmode': 'json'
                }
                fetch_resp = requests.get(fetch_url, params=fetch_params, timeout=10)
                article = fetch_resp.json()['result'][idlist[0]]
                
                return {
                    'title': article.get('title', ''),
                    'source': f"PubMed - {article.get('source', '')}",
                    'url': f"https://pubmed.ncbi.nlm.nih.gov/{idlist[0]}/"
                }
        except Exception as e:
            print(f"PubMedæŠ“å–å¤±è´¥: {str(e)}")
        return None
    
    def generate_content(self, topic):
        """ç”¨AIç”Ÿæˆç§‘æ™®è§£è¯»"""
        if not topic:
            return self.fallback_content()
        
        prompt = f"""ä½ æ˜¯ä¸€ä½åŒ»å­¦ç§‘æ™®åšä¸»ï¼Œè¯·åŸºäºä»¥ä¸‹ä»Šæ—¥çƒ­ç‚¹è¯é¢˜ï¼Œå†™ä¸€ç¯‡ã€æœ‹å‹åœˆé£æ ¼çš„ç§‘æ™®çŸ­æ–‡ã€‘ï¼ˆæ€»å­—æ•°<400å­—ï¼Œç¦æ­¢Markdownç¬¦å·ï¼Œåªèƒ½ç”¨emojiå’Œä¸­æ–‡ï¼‰ã€‚

ã€ä»Šæ—¥è¯é¢˜ã€‘
æ¥æºï¼š{topic.get('source', 'ç½‘ç»œ')}
æ ‡é¢˜ï¼š{topic.get('title', '')}
{topic.get('summary', '')}

ã€è¦æ±‚ã€‘ï¼š
ğŸ§  ç°è±¡è§£è¯»ï¼šä¸ºä»€ä¹ˆå¤§å®¶å…³æ³¨è¿™ä¸ªè¯é¢˜ï¼Ÿï¼ˆç”¨1å¥è¯ç‚¹å‡ºç—›ç‚¹ï¼‰
ğŸ“– ç§‘å­¦åŸç†ï¼šç”¨å¤§ç™½è¯è§£é‡Šæœºåˆ¶ï¼ˆ100å­—å†…ï¼‰
âœ… æ­£ç¡®åšæ³•ï¼šç»™3æ¡å…·ä½“å¯æ“ä½œçš„å»ºè®®ï¼ˆå¦‚ï¼š1.æ¯å¤©7å°æ—¶ç¡çœ  2.ç¡å‰1å°æ—¶ä¸çœ‹æ‰‹æœº 3.å§å®¤æ¸©åº¦20åº¦ï¼‰
âŒ å¸¸è§è¯¯åŒºï¼šè¾Ÿè°£1ä¸ªç›¸å…³é”™è¯¯è®¤çŸ¥

ã€é£æ ¼ã€‘ï¼š
â€¢ åƒæœ‹å‹åˆ†äº«ç»éªŒï¼Œä¸è¦è¯´æ•™
â€¢ æ¯æ®µç”¨emojiå¼€å¤´
â€¢ ç¦æ­¢ç”¨# * - > ã€ã€‘ç­‰ç¬¦å·
â€¢ ä¸­æ–‡è¡¨è¾¾ï¼Œä¸“ä¸šæœ¯è¯­è¦è§£é‡Š
"""
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.7,
            'max_tokens': 800
        }
        
        try:
            response = requests.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=60
            )
            result = response.json()
            content = result['choices'][0]['message']['content']
            
            # æ¸…ç†æ ¼å¼
            content = (content
                      .replace('#', '')
                      .replace('**', '')
                      .replace('*', '')
                      .replace('- ', '')
                      .replace('`', '')
                      .replace('>', '')
                      .replace('ã€', '')
                      .replace('ã€‘', ''))
            
            return content
            
        except Exception as e:
            print(f"AIç”Ÿæˆå¤±è´¥: {str(e)}")
            return self.fallback_content(topic)
    
    def fallback_content(self, topic=None):
        """å¤‡ç”¨å†…å®¹ï¼ˆAIæˆ–ç½‘ç»œå¤±è´¥æ—¶ç”¨ï¼‰"""
        if topic:
            return f"""ğŸ§  ä»Šæ—¥è¯é¢˜ï¼š{topic['title']}

ğŸ“– ç§‘å­¦è§£è¯»ï¼šè¿™ä¸ªè¯é¢˜æ¶‰åŠå¥åº·ç§‘å­¦ä¸æ—¥å¸¸ç”Ÿæ´»çš„äº¤å‰ï¼Œå»ºè®®æŸ¥é˜…æƒå¨åŒ»å­¦æœŸåˆŠè·å–è¯¦ç»†ä¿¡æ¯ã€‚

âœ… å»ºè®®åšæ³•ï¼š
â€¢ å…³æ³¨æƒå¨åŒ»å­¦æœºæ„å‘å¸ƒçš„æŒ‡å—
â€¢ å’¨è¯¢ä¸“ä¸šåŒ»å¸ˆè·å–ä¸ªæ€§åŒ–å»ºè®®
â€¢ ä¿æŒæ‰¹åˆ¤æ€§æ€ç»´ï¼Œè¾¨åˆ«ç½‘ç»œä¿¡æ¯

âŒ æ³¨æ„è¾Ÿè°£ï¼šç½‘ç»œä¿¡æ¯éœ€è°¨æ…ç”„åˆ«ï¼Œè¯·ä»¥ã€Šä¸­å›½å±…æ°‘è†³é£ŸæŒ‡å—ã€‹ç­‰å®˜æ–¹æ–‡ä»¶ä¸ºå‡†

ğŸ“š æ¥æºï¼š{topic.get('source', 'ç½‘ç»œ')} | {topic.get('url', '')}"""
        else:
            return """ğŸ§  ä»Šæ—¥ç§‘æ™®ï¼šå¥åº·ç”Ÿæ´»æ–¹å¼çš„é‡è¦æ€§

ğŸ“– ç§‘å­¦åŸç†ï¼šWHOç ”ç©¶è¡¨æ˜ï¼Œç”Ÿæ´»æ–¹å¼å å¥åº·å½±å“å› ç´ 60%ä»¥ä¸Šã€‚

âœ… ä»Šæ—¥å»ºè®®ï¼š
â€¢ ä¿æŒ7-8å°æ—¶ä¼˜è´¨ç¡çœ 
â€¢ æ¯å¤©30åˆ†é’Ÿä¸­ç­‰å¼ºåº¦è¿åŠ¨
â€¢ å¤šåƒè”¬èœæ°´æœï¼Œé™åˆ¶æ·»åŠ ç³–

âŒ è¯¯åŒºæé†’ï¼šä¸è¦ç›²ç›®ç›¸ä¿¡åæ–¹ï¼Œå¾ªè¯åŒ»å­¦æ‰æ˜¯é‡‘æ ‡å‡†"""
    
    def run(self):
        print("å¼€å§‹æŠ“å–è”ç½‘æ•°æ®...")
        
        # å¤šæºæŠ“å–ï¼Œä¼˜å…ˆçº§ï¼šçŸ¥ä¹ > WHO > PubMed
        topic = None
        sources_checked = []
        
        topic = self.fetch_zhihu_health()
        sources_checked.append("çŸ¥ä¹")
        if topic:
            print(f"ä»çŸ¥ä¹è·å–è¯é¢˜: {topic['title'][:30]}...")
        else:
            print("çŸ¥ä¹æ— æ•°æ®ï¼Œå°è¯•WHO...")
            topic = self.fetch_who_daily()
            sources_checked.append("WHO")
            
        if not topic:
            print("WHOæ— æ•°æ®ï¼Œå°è¯•PubMed...")
            topic = self.fetch_pubmed_today()
            sources_checked.append("PubMed")
        
        if not topic:
            print("æ‰€æœ‰ç½‘ç»œæºå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°å¤‡ç”¨...")
            topic = {
                'title': 'ä»Šæ—¥å¥åº·å»ºè®®',
                'source': 'æœ¬åœ°çŸ¥è¯†åº“',
                'url': ''
            }
        
        print(f"ä½¿ç”¨æ•°æ®æº: {topic.get('source', 'æœªçŸ¥')}")
        
        # ç”Ÿæˆå†…å®¹
        content = self.generate_content(topic)
        
        # ç»„è£…é¡µè„š
        footer = f"""
ğŸ’¡ è¯é¢˜æ¥æºï¼š{topic.get('source', 'ç»¼åˆ')} 
ğŸ”— åŸæ–‡é“¾æ¥ï¼š{topic.get('url', 'è¯¦è§ç›¸å…³æŠ¥é“')}
ğŸ“¡ æ•°æ®æŠ“å–ï¼š{'/'.join(sources_checked)} | ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%H:%M')}
âš–ï¸ å…è´£å£°æ˜ï¼šä»…ä¾›å‚è€ƒï¼Œå…·ä½“è¯Šç–—è¯·å’¨è¯¢åŒ»å¸ˆ
"""
        
        full_message = content + footer
        self.send_feishu(full_message)
        print("æ¨é€å®Œæˆ")
    
    def send_feishu(self, text):
        if not self.feishu_url:
            print("æœªé…ç½®é£ä¹¦")
            return
            
        try:
            payload = {
                "msg_type": "text",
                "content": {"text": f"ğŸŒ æ¯æ—¥å¥åº·é€Ÿé€’ | {datetime.now().strftime('%m-%d')}\n\n{text}"}
            }
            response = requests.post(self.feishu_url, json=payload)
            print(f"æ¨é€çŠ¶æ€: {response.status_code}")
        except Exception as e:
            print(f"æ¨é€å¤±è´¥: {str(e)}")

if __name__ == '__main__':
    bot = LifeScienceWeb()
    bot.run()
