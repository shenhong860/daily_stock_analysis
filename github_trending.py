import os
import requests
from datetime import datetime
from bs4 import BeautifulSoup
import argparse
import re

class GitHubTrendingAnalyzer:
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'deepseek-reasoner')
        self.feishu_url = os.getenv('GITHUB_FEISHU_URL')
        
    def fetch_trending(self, language):
        """æŠ“å– GitHub Trending é¡µé¢"""
        url = f"https://github.com/trending/{language}?since=daily"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        try:
            response = requests.get(url, headers=headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            repos = []
            # GitHub trending é¡µé¢ç»“æ„
            articles = soup.find_all('article', class_='Box-row')
            
            for article in articles[:5]:  # å‰5ä¸ª
                # æå–ä»“åº“å
                h2 = article.find('h2')
                if not h2:
                    continue
                    
                repo_name = h2.get_text(strip=True).replace(' ', '')
                
                # æå–æè¿°
                p = article.find('p', class_='col-9')
                description = p.get_text(strip=True) if p else "æš‚æ— æè¿°"
                
                # æå–æ˜Ÿæ˜Ÿæ•°
                stars_span = article.find('span', class_='d-inline-block')
                stars = "æœªçŸ¥"
                if stars_span:
                    stars_text = stars_span.get_text(strip=True)
                    match = re.search(r'([\d,]+)', stars_text)
                    if match:
                        stars = match.group(1)
                
                # æå–ä»Šæ—¥æ–°å¢starsï¼ˆå¦‚æœæœ‰ï¼‰
                today_stars = ""
                added_span = article.find('span', class_='d-inline-block', string=re.compile(r'today|stars today'))
                if added_span:
                    today_stars = added_span.get_text(strip=True)
                
                repos.append({
                    'name': repo_name,
                    'description': description,
                    'stars': stars,
                    'today_stars': today_stars,
                    'language': language,
                    'url': f"https://github.com/{repo_name}"
                })
                
            return repos
            
        except Exception as e:
            print(f"æŠ“å– {language} å¤±è´¥: {str(e)}")
            return []
    
    def analyze_repo(self, repo):
        """ç”¨ DeepSeek åˆ†æä»“åº“äº®ç‚¹"""
        prompt = f"""ä½ æ˜¯èµ„æ·±å¼€æºé¡¹ç›®åˆ†æå¸ˆï¼Œè¯·ç”¨æç®€è¯­è¨€æ€»ç»“è¿™ä¸ªGitHubé¡¹ç›®ï¼ˆé™åˆ¶æ€»å­—æ•°<150å­—ï¼‰ï¼š

ä»“åº“ï¼š{repo['name']}
è¯­è¨€ï¼š{repo['language']}
æè¿°ï¼š{repo['description']}
æ€»Starï¼š{repo['stars']} | ä»Šæ—¥æ–°å¢ï¼š{repo['today_stars']}

è¯·è¾“å‡ºï¼š
ğŸ’¡ **ä¸€å¥è¯å®šä½**ï¼šè¿™æ˜¯ä»€ä¹ˆå·¥å…·/åº“ï¼Ÿï¼ˆå¦‚ï¼š"æç®€Pythonçˆ¬è™«æ¡†æ¶"ï¼‰
ğŸš€ **è§£å†³ç—›ç‚¹**ï¼šè§£å†³äº†ä»€ä¹ˆå…·ä½“é—®é¢˜ï¼Ÿï¼ˆå¦‚ï¼š"æ¯”Scrapyè½»é‡10å€"ï¼‰
ğŸ¯ **é€‚åˆè°**ï¼šæ¨èç»™ä»€ä¹ˆåœºæ™¯/äººç¾¤ï¼Ÿï¼ˆå¦‚ï¼š"é€‚åˆå¿«é€ŸæŠ“å–ä¸­å°è§„æ¨¡æ•°æ®"ï¼‰

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
ğŸ’¡ APIæ€§èƒ½æµ‹è¯•å·¥å…· | ğŸš€ æ¯”Postmanè½»é‡ï¼Œæ”¯æŒè‡ªåŠ¨åŒ–å‹æµ‹ | ğŸ¯ åç«¯å¼€å‘è‡ªæµ‹æ¥å£ç”¨
"""
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.5,
            'max_tokens': 400
        }
        
        try:
            response = requests.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=30
            )
            result = response.json()
            return result['choices'][0]['message']['content']
        except Exception as e:
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def send_feishu(self, content):
        """æ¨é€åˆ°é£ä¹¦"""
        if not self.feishu_url:
            print("æœªé…ç½®é£ä¹¦ Webhook")
            return
            
        formatted = f"""
ğŸ”¥ **GitHub ä»Šæ—¥çƒ­ç‚¹** | {datetime.now().strftime('%Y-%m-%d')}

{content}

---
â­ æ•°æ®æ¥æºï¼šGitHub Trending | ç”± DeepSeek-R1 é€Ÿè¯»
        """
        
        payload = {
            "msg_type": "text",
            "content": {
                "text": formatted
            }
        }
        
        requests.post(self.feishu_url, json=payload)
        print("GitHub Trending æ¨é€æˆåŠŸ")
    
    def run(self, languages_str):
        languages = [l.strip() for l in languages_str.split(',')]
        
        full_report = ""
        total_repos = 0
        
        for lang in languages:
            print(f"æ­£åœ¨æŠ“å– {lang} æ¦œå•...")
            repos = self.fetch_trending(lang)
            
            if not repos:
                continue
                
            full_report += f"\nğŸ“Œ **{lang.upper()}** æ¦œ Top {len(repos)}:\n\n"
            
            for i, repo in enumerate(repos, 1):
                print(f"  åˆ†æ {repo['name']}...")
                analysis = self.analyze_repo(repo)
                
                # çŸ­æ ¼å¼è¾“å‡º
                full_report += f"{i}. **{repo['name']}** â­{repo['stars']}\n"
                full_report += f"   {analysis}\n"
                full_report += f"   ğŸ”— {repo['url']}\n\n"
                
            total_repos += len(repos)
        
        if total_repos == 0:
            self.send_feishu("ğŸ“­ ä»Šæ—¥ GitHub Trending æŠ“å–å¤±è´¥æˆ–è¢«åçˆ¬ï¼Œè¯·ç¨åé‡è¯•")
            return
            
        self.send_feishu(full_report)
        print(f"å®Œæˆï¼åˆ†æäº† {total_repos} ä¸ªä»“åº“")

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--languages', default='python,typescript', help='ç¼–ç¨‹è¯­è¨€åˆ—è¡¨')
    args = parser.parse_args()
    
    analyzer = GitHubTrendingAnalyzer()
    analyzer.run(args.languages)
