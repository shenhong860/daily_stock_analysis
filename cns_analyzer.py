import os
import requests
import feedparser
from datetime import datetime

class CNSAnalyzer:
    """åªç›‘æ§CNSä¸»åˆŠåŠå¤§å­åˆŠ"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = os.getenv('OPENAI_BASE_URL', 'https://api.deepseek.com/v1')
        self.model = os.getenv('OPENAI_MODEL', 'deepseek-reasoner')
        self.feishu_url = os.getenv('CNS_FEISHU_URL')
        
        # CNSåŠå¤§å­åˆŠRSSï¼ˆä¸¥æ ¼ç­›é€‰ï¼‰
        self.journals = {
            'Nature': 'https://www.nature.com/nature.rss',
            'Nature Medicine': 'https://www.nature.com/nm.rss',
            'Nature Cancer': 'https://www.nature.com/natcancer.rss',
            'Cell': 'https://www.cell.com/cell/current.rss',
            'Cancer Cell': 'https://www.cell.com/cancer-cell/current.rss',
            'Cell Stem Cell': 'https://www.cell.com/cell-stem-cell/current.rss',
            'Immunity': 'https://www.cell.com/immunity/current.rss',
            'Science': 'https://www.science.org/rss/news_current.xml',
            'Science Translational Medicine': 'https://www.science.org/rss/tm_current.xml',
            'Molecular Cell': 'https://www.cell.com/molecular-cell/current.rss',
            'Nature Cell Biology': 'https://www.nature.com/ncb.rss',
            'Nature Immunology': 'https://www.nature.com/ni.rss',
            'Cell Metabolism': 'https://www.cell.com/cell-metabolism/current.rss',
            'Neuron': 'https://www.cell.com/neuron/current.rss'
        }
        
        # å…³é”®è¯è¿‡æ»¤ï¼ˆåªä¿ç•™åŒ»å­¦/åˆ†å­ç”Ÿç‰©å­¦ç›¸å…³ï¼‰
        self.keywords = [
            'cancer', 'tumor', 'immunotherapy', 'single-cell', 'spatial',
            'CRISPR', 'genome', 'transcriptome', 'proteomics', 'metabolism',
            'stem cell', 'differentiation', 'microenvironment', 'signaling',
            'pathway', 'mechanism', 'therapeutic', 'clinical trial'
        ]
    
    def fetch_cns_papers(self):
        """æŠ“å–å„é¡¶åˆŠæœ€æ–°æ–‡ç« """
        papers = []
        
        for journal_name, rss_url in self.journals.items():
            try:
                feed = feedparser.parse(rss_url)
                # åªå–æœ€è¿‘24å°æ—¶çš„å‰2ç¯‡
                for entry in feed.entries[:2]:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç”Ÿç‰©åŒ»å­¦ç›¸å…³
                    content = f"{entry.title} {entry.get('summary', '')}".lower()
                    
                    if any(k in content for k in self.keywords):
                        papers.append({
                            'title': entry.title,
                            'journal': journal_name,
                            'link': entry.link,
                            'summary': entry.get('summary', '')[:500],
                            'published': entry.get('published', 'Today')
                        })
                        
                        if len(papers) >= 5:  # æ¯å¤©æœ€å¤š5ç¯‡ï¼Œä¿è¯è´¨é‡
                            return papers
            except:
                continue
        
        return papers
    
    def deep_analysis(self, paper):
        """å¦‚åŒå¯¼å¸ˆå®¡ç¨¿èˆ¬çš„æ·±åº¦åˆ†æ"""
        prompt = f"""ä½ æ˜¯Cell/NatureæœŸåˆŠçš„èµ„æ·±å®¡ç¨¿äººï¼Œè¯·å¯¹è¿™ç¯‡é¡¶åˆŠæ–‡ç« è¿›è¡Œ"ç ”ç©¶ç”Ÿç»„ä¼šæ±‡æŠ¥"çº§åˆ«çš„æ·±åº¦è§£æï¼ˆæ€»å­—æ•°<600å­—ï¼Œä¸¥æ ¼ç»“æ„ï¼‰ï¼š

ã€æ–‡ç« ä¿¡æ¯ã€‘
æœŸåˆŠï¼š{paper['journal']}
æ ‡é¢˜ï¼š{paper['title']}
æ‘˜è¦ç‰‡æ®µï¼š{paper['summary']}

ã€è¦æ±‚è¾“å‡º - ä¸ç¬¦åˆé¡¶åˆŠæ°´å¹³ç›´æ¥æŒ‡å‡ºã€‘ï¼š

ğŸ† **ç ”ç©¶æ¡£æ¬¡**
â€¢ æœŸåˆŠå®åŠ›ï¼š{paper['journal']} (IF: {self._get_if(paper['journal'])})
â€¢ ç ”ç©¶ç±»å‹ï¼šæ˜¯ã€æ¦‚å¿µçªç ´ã€‘/ã€æŠ€æœ¯é©å‘½ã€‘/ã€ä¸´åºŠè½¬åŒ–ã€‘/ã€æœºåˆ¶æ·±æŒ–ã€‘ï¼Ÿ
â€¢ ä¸€å¥è¯è¯„çº§ï¼šè¿™å¯èƒ½æ˜¯é¢†åŸŸé‡Œç¨‹ç¢‘/é‡è¦è¡¥å……/ incremental work?

ğŸ§¬ **æ ¸å¿ƒå‘ç°ï¼ˆç²¾åï¼ï¼‰**
â€¢ é¢ è¦†äº†å“ªä¸ªä¼ ç»Ÿè®¤çŸ¥ï¼Ÿæˆ–å¡«è¡¥äº†å“ªä¸ªç©ºç™½ï¼Ÿ
â€¢ å…³é”®å®éªŒè®¾è®¡ï¼šç”¨ä»€ä¹ˆæ–°æŠ€æœ¯/æ¨¡å‹è§£å†³äº†ä»€ä¹ˆè€é—®é¢˜ï¼Ÿ
â€¢ æ•°æ®è§„æ¨¡ï¼šæ¶‰åŠå¤šå°‘æ ·æœ¬/ç»†èƒ/åŸºå› ï¼Ÿï¼ˆä½“ç°å·¥ä½œé‡ï¼‰

ğŸ’Š **åŒ»å­¦æ„ä¹‰ï¼ˆå¦‚æœä½ æ˜¯ä¸´åºŠåŒ»ç”Ÿï¼‰**
â€¢ èƒ½ç«‹åˆ»æ”¹å˜è¯Šç–—æŒ‡å—å—ï¼Ÿè¿˜æ˜¯éœ€è¦10å¹´è½¬åŒ–ï¼Ÿ
â€¢ æ½œåœ¨é¶ç‚¹æ˜¯å¦å·²æœ‰è¯ç‰©å¯ç”¨ï¼Ÿï¼ˆè€è¯æ–°ç”¨ vs å…¨æ–°é¶ç‚¹ï¼‰

âš ï¸ **å®¡ç¨¿äººè§†è§’çš„è´¨ç–‘ï¼ˆCritical Thinkingï¼‰**
â€¢ å®éªŒè®¾è®¡æ˜¯å¦æœ‰æ¼æ´ï¼Ÿï¼ˆå¦‚ï¼šä»…ç”¨ç»†èƒç³»ï¼Œç¼ºä¹ä½“å†…éªŒè¯ï¼‰
â€¢ æœºåˆ¶æ˜¯å¦è¿‡äºç›¸å…³è®ºï¼Œç¼ºä¹å› æœï¼Ÿï¼ˆå¦‚ï¼šä»…ç”¨æ•²ä½ï¼Œæ—  rescueï¼‰
â€¢ æ ·æœ¬æ˜¯å¦æœ‰åå€šï¼Ÿï¼ˆå¦‚ï¼šä»…æ—©æœŸæ‚£è€…ï¼Œæˆ–ç‰¹å®šäººç§ï¼‰

ğŸ¯ **ä½ èƒ½å­¦åˆ°ä»€ä¹ˆï¼Ÿ**
â€¢ æŠ€æœ¯ï¼šå¯è¿ç§»åˆ°ä½ è¯¾é¢˜çš„æ–¹æ³•ï¼ˆå¦‚ï¼šæŸæ–°å‹æµ‹åºæ–¹æ¡ˆï¼‰
â€¢ æ€è·¯ï¼šå¦‚ä½•æå‡ºä¸€ä¸ªå€¼å¾—å‘CNSçš„ç§‘å­¦é—®é¢˜ï¼Ÿ
â€¢ å†™ä½œï¼šæ ‡é¢˜/æ‘˜è¦çš„å“ªäº›æŠ€å·§å€¼å¾—æ¨¡ä»¿ï¼Ÿ

ã€ä¸¥ç¦å¥—è·¯åŒ–è¯„ä»·ï¼Œå¿…é¡»æœ‰å…·ä½“æ‰¹åˆ¤ç‚¹ã€‘
"""
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            'model': self.model,
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.4,  # é™ä½æ¸©åº¦ï¼Œæ›´æ‰¹åˆ¤æ€§
            'max_tokens': 1200
        }
        
        try:
            response = requests.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=90
            )
            return response.json()['choices'][0]['message']['content']
        except Exception as e:
            return f"åˆ†æå¤±è´¥: {str(e)}"
    
    def _get_if(self, journal):
        """ç®€åŒ–IFæ˜ å°„"""
        ifs = {
            'Nature': '64.8', 'Science': '56.9', 'Cell': '64.5',
            'Nature Medicine': '82.9', 'Cancer Cell': '48.8',
            'Cell Stem Cell': '23.9', 'Immunity': '32.4',
            'Nature Cancer': '23.5', 'Science Translational Medicine': '17.1',
            'Molecular Cell': '17.0', 'Neuron': '16.2',
            'Nature Cell Biology': '17.3', 'Nature Immunology': '27.7',
            'Cell Metabolism': '31.3'
        }
        return ifs.get(journal, '20+')
    
    def run(self):
        papers = self.fetch_cns_papers()
        
        if not papers:
            self.send_feishu("ğŸ“­ ä»Šæ—¥CNSæ— ç”Ÿç‰©åŒ»å­¦ç›¸å…³æ–°æ–‡ï¼Œæˆ–æŠ“å–è¢«å¢™")
            return
        
        report = f"ğŸ“Š æ‰«æ {len(self.journals)} æœ¬é¡¶åˆŠï¼Œç²¾é€‰ {len(papers)} ç¯‡\n\n"
        
        for i, paper in enumerate(papers, 1):
            analysis = self.deep_analysis(paper)
            report += f"â”â”â”â”â”â”â”â”â”â”â”â”\nã€{i}ã€‘{paper['journal']} | {paper['title'][:60]}...\n{analysis}\nğŸ”— {paper['link']}\n\n"
        
        self.send_feishu(report)
        print(f"CNSæ¨é€å®Œæˆï¼Œå…±{len(papers)}ç¯‡")
    
    def send_feishu(self, text):
        if not self.feishu_url:
            print("æœªé…ç½®é£ä¹¦")
            return
            
        payload = {
            "msg_type": "text",
            "content": {"text": f"ğŸ† **CNSæ™¨è¯»** | {datetime.now().strftime('%m-%d')}\n\n{text}"}
        }
        requests.post(self.feishu_url, json=payload)

if __name__ == '__main__':
    analyzer = CNSAnalyzer()
    analyzer.run()
